# CT_RSA

.\.venv\Scripts\Activate.ps1

python et le nom du fichier

pour fetch_ct.py || python fetch_ct.py

deactivate

Certificats, web et calculs de cl√©s priv√©es
‚Äî R√©cup√©rer au moins 1 million de certificats en utilisant Certificate Transparency en √©crivant un crawler
et en t√©l√©chargeant les certificats de la PKI Certificate Transparancy utilisant les API publiques
document√©es [6]. La liste des API pour r√©cup√©rer les donn√©es est d√©crite par une RFC. [7]
‚Äî Trier les cl√©s par taille
‚Äî Recherche de doublons (cl√©s identiques)
‚Äî Recherche de cl√©s diff√©rentes, mais ayant un facteur commun
‚Äî Lancer Batch GCD [1] sur les autres cl√©s, il est possible de trouver soit p soit q commun a une cl√©
sachant que n = pq
‚Äî Bacth GCD existe en Python et en C++, ne pas le recoder !

fetch_ct.py

üß© 1. Objectif global du script

Le but du fichier fetch_ct.py est de t√©l√©charger les certificats d‚Äôun CT log (Certificate Transparency log), comme Argon2024 de Google.
Ces logs contiennent tous les certificats TLS publics √©mis dans le monde, sous forme d‚Äôentr√©es num√©rot√©es.

Chaque entr√©e a un index (0, 1, 2, 3, ‚Ä¶).
Ce script va donc :

T√©l√©charger les entr√©es de ce log (de mani√®re efficace).

Les stocker dans des fichiers compress√©s .jsonl.gz.

Sauvegarder sa progression dans data/state.json pour pouvoir reprendre l√† o√π il s‚Äôest arr√™t√©.

üß≠ 2. Fonctionnement g√©n√©ral du script

Voici les √©tapes globales :

Charger la position du dernier t√©l√©chargement (dans state.json).

Cr√©er un dossier de sortie data/raw/shard_xxxx.

T√©l√©charger les certificats (en parall√®le, avec plusieurs connexions).

Sauvegarder les certificats compress√©s (.jsonl.gz).

Enregistrer le nouvel index dans state.json.

Recommencer avec le shard suivant, jusqu‚Äô√† 1 million.

üß† 3. D√©composition du code

Je vais t‚Äôexpliquer section par section :

üß± En-t√™te et imports
import asyncio
import aiohttp
import json
import gzip
import os
import logging
from pathlib import Path

asyncio : permet d‚Äôex√©cuter plusieurs t√©l√©chargements en parall√®le sans bloquer.

aiohttp : biblioth√®que HTTP asynchrone (tr√®s rapide).

json, gzip : pour sauvegarder les donn√©es dans un format compress√©.

logging : pour enregistrer les logs d‚Äôex√©cution.

Path : facilite la manipulation des chemins de fichiers.

‚öôÔ∏è Param√®tres de configuration
CT_LOG_URL = "https://ct.googleapis.com/logs/argon2024"
SHARD_SIZE = 10_000
CONCURRENCY = 10
STATE_FILE = Path("data/state.json")
OUTPUT_DIR = Path("data/raw")
LOG_FILE = Path("data/logs/fetch.log")
TIMEOUT = aiohttp.ClientTimeout(total=30)

CT_LOG_URL : l‚ÄôURL du log CT √† interroger (ici Argon2024 de Google).

SHARD_SIZE : nombre d‚Äôentr√©es √† regrouper dans un "shard" (bloc de fichiers).
‚Üí chaque shard = un paquet de 10 000 certificats.

CONCURRENCY : nombre de t√©l√©chargements simultan√©s (10 en parall√®le).

STATE_FILE : fichier o√π on enregistre la progression (data/state.json).

OUTPUT_DIR : dossier o√π sont stock√©s les r√©sultats (data/raw/).

LOG_FILE : fichier de log (data/logs/fetch.log).

TIMEOUT : limite de temps (30 s max par requ√™te HTTP).

üßÆ Gestion de l‚Äô√©tat
def load_state():
if STATE_FILE.exists():
with open(STATE_FILE, "r") as f:
return json.load(f)
return {"next_index": 0}

def save_state(state):
STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
with open(STATE_FILE, "w") as f:
json.dump(state, f)

‚û°Ô∏è Ces deux fonctions g√®rent la reprise automatique :

load_state() lit le fichier state.json pour savoir √† quel index reprendre.

save_state() enregistre l‚Äôindex courant (pour relancer plus tard).

Exemple :
si ton script s‚Äôarr√™te √† 50 000, quand tu relances, il reprendra √† 50 000.

üåê T√©l√©chargement d‚Äôune entr√©e individuelle
async def fetch_entry(session, index):
url = f"{CT_LOG_URL}/ct/v1/get-entries?start={index}&end={index}"
try:
async with session.get(url) as resp:
if resp.status == 200:
data = await resp.json()
return data["entries"][0]
else:
logging.warning(f"Erreur HTTP {resp.status} pour index {index}")
except Exception as e:
logging.error(f"Exception √† l'index {index}: {e}")
return None

Cette fonction :

T√©l√©charge une entr√©e unique (certificat) du CT log, √† l‚Äôindex donn√©.

Si la requ√™te r√©ussit (status 200), elle renvoie le contenu JSON.

Sinon, elle logue une erreur et retourne None.

async def ‚Üí cela veut dire que cette fonction est asynchrone :
elle peut tourner en m√™me temps que d‚Äôautres (parall√©lisme).

‚ö° T√©l√©chargement d‚Äôun bloc complet
async def fetch_block(session, start, end):
results = []
sem = asyncio.Semaphore(CONCURRENCY)

    async def worker(i):
        async with sem:
            entry = await fetch_entry(session, i)
            if entry:
                results.append({
                    "index": i,
                    "leaf_input": entry.get("leaf_input"),
                    "extra_data": entry.get("extra_data")
                })

    await asyncio.gather(*[worker(i) for i in range(start, end)])
    return results

Cette fonction t√©l√©charge tous les certificats d‚Äôun bloc [start, end) :

Cr√©e une s√©maphore pour limiter √† CONCURRENCY (10 t√¢ches en m√™me temps).

Lance une t√¢che worker() pour chaque index.

asyncio.gather() ex√©cute tout en parall√®le.

Chaque entry est stock√©e dans results.

üëâ Ce bloc est le c≈ìur du parall√©lisme :
il permet de t√©l√©charger rapidement des milliers d‚Äôentr√©es sans saturer le serveur.

üöÄ Fonction principale
async def main():
state = load_state()
start_index = state["next_index"]
Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

    async with aiohttp.ClientSession(timeout=TIMEOUT) as session:
        while True:
            shard_id = start_index // SHARD_SIZE
            shard_dir = OUTPUT_DIR / f"shard_{shard_id:04d}"
            shard_dir.mkdir(parents=True, exist_ok=True)
            end_index = start_index + SHARD_SIZE

            logging.info(f"T√©l√©chargement shard {shard_id} [{start_index}‚Äì{end_index})")
            block = await fetch_block(session, start_index, end_index)

            if not block:
                logging.warning("Aucune donn√©e re√ßue, arr√™t.")
                break

            output_file = shard_dir / f"certs_{start_index:08d}_{end_index:08d}.jsonl.gz"
            with gzip.open(output_file, "wt", encoding="utf-8") as gz:
                for entry in block:
                    gz.write(json.dumps(entry) + "\n")

            logging.info(f"Shard {shard_id} termin√© ‚Äî {len(block)} entr√©es")
            start_index = end_index
            state["next_index"] = start_index
            save_state(state)

            if start_index >= 1_000_000:
                logging.info("Objectif 1M atteint, arr√™t.")
                break

C‚Äôest le chef d‚Äôorchestre :

Charge la position du dernier t√©l√©chargement.

Cr√©e un client HTTP (session).

Tant qu‚Äôon n‚Äôa pas atteint 1M :

Calcule quel shard on traite (0000, 0001, ‚Ä¶).

T√©l√©charge les entr√©es du bloc (fetch_block).

√âcrit le r√©sultat dans un fichier compress√© .jsonl.gz.

Met √† jour state.json avec la nouvelle position.

Passe au shard suivant.

Chaque fichier de sortie contiendra 10 000 lignes JSON, compress√©es.

üèÅ Point d‚Äôentr√©e du programme
if **name** == "**main**":
asyncio.run(main())

‚û°Ô∏è Cela lance la fonction main() dans la boucle asynchrone asyncio.

üîÑ 4. Ce qu‚Äôil se passe quand tu ex√©cutes le code

Quand tu tapes :

python fetch_ct.py

Voici ce qui se passe √©tape par √©tape :

Le script lit data/state.json (ou cr√©e un nouvel √©tat {next_index: 0}).

Il se connecte au log CT https://ct.googleapis.com/logs/argon2024.

Il commence √† t√©l√©charger les certificats √† partir de l‚Äôindex 0.

Il lance 10 t√©l√©chargements simultan√©s en boucle jusqu‚Äô√† 10 000 (le premier shard).

Les r√©sultats sont enregistr√©s dans :

data/raw/shard_0000/certs_00000000_00010000.jsonl.gz

Puis il met √† jour :

data/state.json ‚Üí {"next_index": 10000}

Ensuite il t√©l√©charge le shard suivant :

shard_0001 : 10000 √† 20000

Et ainsi de suite jusqu‚Äô√† 1 million.

Si tu arr√™tes le script, puis le relances, il reprend exactement √† la derni√®re position.

üì¶ Exemple concret de fichier de sortie

Un fichier .jsonl.gz contient du JSON compress√© ligne par ligne.
Chaque ligne correspond √† une entr√©e du CT log :

{"index": 12345, "leaf_input": "MII...", "extra_data": "MII..."}
{"index": 12346, "leaf_input": "MII...", "extra_data": "MII..."}
...

Ce sont les certificats cod√©s en base64.
Ton script parse_cert.py servira ensuite √† extraire les vraies cl√©s RSA √† partir de ces donn√©es.

parse_cert.py

üß≠ 1. Objectif de parse_cert.py

Le script :

Lit les fichiers produits par fetch_ct.py (data/raw/shard_xxxx/\*.jsonl.gz),

D√©code les champs leaf_input et extra_data (base64) pour reconstruire les certificats X.509,

Extrait la cl√© publique RSA (modulus n, exposant e, taille),

Calcule un hash SHA-256 du modulus pour d√©tecter les doublons,

Enregistre tout dans un fichier Parquet (data/parsed/certs.parquet), format rapide et compress√©.

üß© 2. Sch√©ma de donn√©es de sortie

Chaque ligne (une cl√©) contiendra :

Champ###################Type########Description

index###################int#########Index du certificat dans le CT log
key_size################int#########Taille en bits de la cl√© RSA
exponent################int#########Exposant public
modulus_hex#############str#########Modulus (cl√© publique) en hexad√©cimal
modulus_sha256##########str#########Hash SHA-256 du modulus
subject#################str#########Nom du propri√©taire du certificat
issuer##################str#########Autorit√© √©mettrice
not_before##############str#########Date de d√©but de validit√©
not_after###############str#########Date de fin de validit√©
shard###################str#########Nom du shard d‚Äôorigine
